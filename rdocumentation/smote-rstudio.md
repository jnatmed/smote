## documentacion SMOTE rstudio

SMOTE: Algoritmo SMOTE para problemas de clasificación no balanceada 

#### Descripción 

Esta función maneja problemas de clasificación no balanceada utilizando el método SMOTE. Es decir, puede generar un nuevo conjunto de datos "SMOTEd" que aborda el problema del desequilibrio de clases. Alternativamente, también puede ejecutar un algoritmo de clasificación en este nuevo conjunto de datos y devolver el modelo resultante.

#### argumentos

- Forma -> Una fórmula que describe los datos del problema de predicción 
- Datos -> Un marco de datos que contiene el conjunto de datos original (desequilibrado) 
- perc.over -> Un número que impulsa la decisión de cuántos casos adicionales de la clase minoritaria se generan (conocido como sobremuestreo). 
- k -> Un número que indica el número de vecinos más cercanos que se utilizan para generar los nuevos ejemplos de la clase minoritaria. 
- perc.under -> Un número que impulsa la decisión de cuántos casos adicionales de las clases mayoritarias se seleccionan para cada caso generado a partir de la clase minoritaria (conocido como submuestreo) 
- alumno -> Opcionalmente, puede especificar una cadena con el nombre de una función que implementa un algoritmo de clasificación que se aplicará al conjunto de datos SMOTEd resultante (predeterminado en NULL). ... En caso de que especifique un alumno (aprendiz de parámetro), puede indicar más argumentos que se utilizarán al llamar a este alumno.

#### Valor

La función puede devolver dos tipos diferentes de valores dependiendo del valor del alumno del parámetro. Si este parámetro es NULL (por defecto), la función devolverá un marco de datos con el nuevo conjunto de datos resultante de la aplicación del algoritmo SMOTE. De lo contrario, la función devolverá el modelo de clasificación obtenido por el alumno especificado en el parámetro alumno. Detalles Los problemas de clasificación desequilibrada causan problemas a muchos algoritmos de aprendizaje. Estos problemas se caracterizan por la proporción desigual de casos disponibles para cada clase del problema. SMOTE (Chawla et. al. 2002) es un algoritmo bien conocido para combatir este problema. La idea general de este método es generar artificialmente nuevos ejemplos de la clase minoritaria utilizando los vecinos más cercanos de estos casos. Además, los ejemplos de la clase mayoritaria también están submuestreados, lo que lleva a un conjunto de datos más equilibrado. Los parámetros perc.over y perc.under controlan la cantidad de sobremuestreo de la clase minoritaria y submuestreo de las clases mayoritarias, respectivamente. perc.over será típicamente un número por encima de 100. Con este tipo de valores, para cada caso en el conjunto de datos original perteneciente a la clase minoritaria, se crearán perc.over/100 nuevos ejemplos de esa clase. Si perc.over es un valor inferior a 100, se generará un solo caso para una proporción seleccionada aleatoriamente (dada por perc.over/100) de los casos que pertenecen a la clase minoritaria en el conjunto de datos original. El parámetro perc.under controla la proporción de casos de la clase mayoritaria que se seleccionarán aleatoriamente para el conjunto de datos "equilibrado" final. Esta proporción se calcula con respecto al número de casos de clases minoritarias recién generados. Por ejemplo, si se generaron 200 nuevos ejemplos para la clase minoritaria, un valor de perc.under de 100 seleccionará aleatoriamente exactamente 200 casos pertenecientes a las clases mayoritarias del conjunto de datos original para pertenecer al conjunto de datos final. Los valores por encima de 100 seleccionarán más ejemplos de las clases mayoritarias. El parámetro k controla la forma en que se crean los nuevos ejemplos. Para cada ejemplo de clase minoritaria actualmente existente, se crearán X nuevos ejemplos (esto está controlado por el parámetro perc.over como se mencionó anteriormente). Estos ejemplos se generarán utilizando la información de los k vecinos más cercanos de cada ejemplo de la clase minoritaria. El parámetro k controla cuántos de estos vecinos se utilizan. La función también se puede utilizar para obtener directamente el modelo de clasificación del conjunto de datos equilibrado resultante. Esto se puede hacer incluyendo el nombre de la función R que implementa el clasificador en el alumno de parámetros. También puede incluir otros parámetros que serán importantes para esta función de aprendizaje. Si el parámetro de aprendizaje no es NULL (el valor predeterminado), el valor de retorno de la función será el modelo aprendido y no el conjunto de datos equilibrado. La función que aprende el modelo debe tener como primer parámetro la fórmula que describe el problema de clasificación y en el segundo argumento el conjunto de entrenamiento.


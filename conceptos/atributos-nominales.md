## 2.1.2 Atributos Nominales 

Nominal significa “relativo a los nombres”. Los valores de un atributo nominal son símbolos o nombres de cosas. Cada valor representa algún tipo de categoría, código o estado, por lo que los atributos nominales también se conocen como categóricos. Los valores no tienen ningún orden significativo. En informática, los valores también se conocen como enumeraciones.

Ejemplo 2.1 Atributos nominales. Supongamos que el color del cabello y el estado civil son dos atributos que describen objetos de personas. En nuestra aplicación, los valores posibles para el color del cabello son negro, castaño, rubio, rojo, castaño rojizo, gris y blanco. El atributo estado civil puede tomar los valores soltero, casado, divorciado y viudo. Tanto el color del cabello como el estado civil son atributos nominales. Otro ejemplo de atributo nominal es la ocupación, con los valores profesor, dentista, programador, agricultor, etc.

- Los conjuntos de datos están formados por objetos de datos. Un objeto de datos representa una entidad. Los objetos de datos se describen mediante atributos. 
- Los atributos pueden ser nominales, binarios, ordinales o numéricos. 
- Los valores de un atributo nominal (o categórico) son símbolos o nombres de cosas, donde cada valor representa algún tipo de categoría, código o estado. 
- Los atributos binarios son atributos nominales con solo dos estados posibles (como 1 y 0 o verdadero y falso). Si los dos estados son igualmente importantes, el atributo es simétrico; de lo contrario, es asimétrico. 
- Un atributo ordinal es un atributo con valores posibles que tienen un orden significativo o una clasificación entre ellos, pero no se conoce la magnitud entre los valores sucesivos. Un atributo numérico es cuantitativo (es decir, es una cantidad medible) representado en valores enteros o reales. Los tipos de atributos numéricos pueden tener una escala de intervalo o una escala de proporción. Los valores de un atributo escalado por intervalos se miden en unidades fijas e iguales. Los atributos de escala proporcional son atributos numéricos con un punto cero inherente. 
- Las medidas tienen una escala de proporción en la que podemos hablar de valores como si fueran un orden de magnitud mayor que la unidad de medida. 
- Las descripciones estadísticas básicas proporcionan la base analítica para el preprocesamiento de datos. Las medidas estadísticas básicas para el resumen de datos incluyen la media, la media ponderada, la mediana y la moda para medir la tendencia central de los datos; y rango, cuantiles, cuartiles, rango intercuartílico, varianza y desviación estándar para medir la dispersión de datos. Las representaciones gráficas (p. ej., diagramas de caja, diagramas de cuantiles, diagramas de cuantiles-cuantiles, histogramas y diagramas de dispersión) facilitan la inspección visual de los datos y, por lo tanto, son útiles para el preprocesamiento y la extracción de datos. 
- Las técnicas de visualización de datos pueden estar orientadas a píxeles, basadas en geometría, basadas en iconos o jerárquicas. Estos métodos se aplican a datos relacionales multidimensionales. Se han propuesto técnicas adicionales para la visualización de datos complejos, como texto y redes sociales. 
- Las medidas de similitud y disimilitud de objetos se utilizan en aplicaciones de minería de datos como la agrupación, el análisis de valores atípicos y la clasificación del vecino más cercano. Estas medidas de proximidad se pueden calcular para cada tipo de atributo estudiado en este capítulo, o para combinaciones de tales atributos. Los ejemplos incluyen el coeficiente de Jaccard para atributos binarios asimétricos y las distancias Euclidiana, Manhattan, Minkowski y suprema para atributos numéricos. Para aplicaciones que involucran vectores de datos numéricos dispersos, como los vectores de frecuencia de términos, la medida del coseno y el coeficiente de Tanimoto se usan a menudo en la evaluación de la similitud.

### 3.5.2 Transformación de datos por normalización 

La unidad de medida utilizada puede afectar el análisis de datos. Por ejemplo, cambiar las unidades de medida de metros a pulgadas para la altura, o de kilogramos a libras para el peso, puede generar resultados muy diferentes. En general, expresar un atributo en unidades más pequeñas conducirá a un rango más amplio para ese atributo y, por lo tanto, tenderá a darle mayor efecto o “peso” a dicho atributo. Para ayudar a evitar la dependencia de la elección de las unidades de medida, los datos deben normalizarse o estandarizarse. Esto implica transformar los datos para que se encuentren dentro de un rango más pequeño o común, como [−1,1] o [0.0, 1.0]. (Los términos estandarizar y normalizar se usan indistintamente en el preprocesamiento de datos, aunque en estadística, el último término también tiene otras connotaciones). La normalización de los datos intenta dar a todos los atributos el mismo peso. La normalización es particularmente útil para los algoritmos de clasificación que involucran redes neuronales o mediciones de distancia, como la clasificación y el agrupamiento del vecino más cercano. Si utiliza el algoritmo de retropropagación de redes neuronales para la minería de clasificación (Capítulo 9), la normalización de los valores de entrada para cada atributo medido en las tuplas de entrenamiento ayudará a acelerar la fase de aprendizaje. Para los métodos basados ​​en la distancia, la normalización ayuda a evitar que los atributos con rangos inicialmente grandes (p. ej., ingresos) superen a los atributos con rangos inicialmente más pequeños (p. ej., atributos binarios). También es útil cuando no se tiene conocimiento previo de los datos. Hay muchos métodos para la normalización de datos. 
Estudiamos la normalización min-max, la normalización de puntuación z y la normalización por escalado decimal. Para nuestra discusión, sea A un atributo numérico con n valores observados, v1, v2,..., vn. La normalización min-max realiza una transformación lineal en los datos originales. Suponga que minA y maxA son los valores mínimo y máximo de un atributo, A. 
La normalización min-max mapea un valor, vi , de A a v 0 i en el rango [new minA,new maxA] calculando

### 3.5.3 Discretización por agrupamiento 

El agrupamiento es una técnica de división de arriba hacia abajo basada en un número específico de contenedores. La Sección 3.2.2 discutió los métodos de agrupamiento para el suavizado de datos. Estos métodos también se utilizan como métodos de discretización para la reducción de datos y la generación de jerarquías de conceptos. Por ejemplo, los valores de los atributos se pueden discretizar aplicando intervalos de igual ancho o igual frecuencia, y luego reemplazando cada valor de intervalo por la media o la mediana del intervalo, como en el suavizado por medias del intervalo o el suavizado por medianas del intervalo, respectivamente. Estas técnicas se pueden aplicar recursivamente a las particiones resultantes para generar jerarquías de conceptos. El agrupamiento no utiliza información de clase y, por lo tanto, es una técnica de discretización no supervisada. Es sensible al número de contenedores especificado por el usuario, así como a la presencia de valores atípicos.

### 3.5.5 Discretización por conglomerados, árboles de decisión y análisis de correlación 

Se pueden utilizar conglomerados, análisis de árboles de decisión y análisis de correlación para la discretización de datos. Estudiamos brevemente cada uno de estos enfoques. El análisis de conglomerados es un método popular de discretización de datos. Se puede aplicar un algoritmo de agrupamiento para discretizar un atributo numérico, A, dividiendo los valores de A en conglomerados o grupos. El agrupamiento tiene en cuenta la distribución de A, así como la cercanía de los puntos de datos y, por lo tanto, puede producir resultados de discretización de alta calidad. La agrupación en clústeres se puede utilizar para generar una jerarquía de conceptos para A siguiendo una estrategia de división de arriba hacia abajo o una estrategia de fusión de abajo hacia arriba, donde cada clúster forma un nodo de la jerarquía de conceptos. En el primero, cada grupo o partición inicial puede descomponerse en varios subgrupos, formando un nivel inferior de la jerarquía. En este último, los grupos se forman agrupando repetidamente grupos vecinos para formar conceptos de nivel superior. Los métodos de agrupación para la minería de datos se estudian en los Capítulos 10 y 11. Las técnicas para generar árboles de decisión para la clasificación (Capítulo 8) se pueden aplicar a la discretización. Tales técnicas emplean un enfoque de división de arriba hacia abajo. A diferencia de los otros métodos mencionados hasta ahora, los enfoques de árbol de decisión para la discretización son supervisados, es decir, hacen uso de la información de la etiqueta de clase. Por ejemplo, podemos tener un conjunto de datos de síntomas de pacientes (los atributos) donde cada paciente tiene una etiqueta de clase de diagnóstico asociada. La información de distribución de clases se utiliza en el cálculo y determinación de puntos de división (valores de datos para dividir un rango de atributos). Intuitivamente, la idea principal es seleccionar puntos de división para que una partición resultante dada contenga tantas tuplas de la misma clase como sea posible. La entropía es la medida más utilizada para este propósito. Para discretizar un atributo numérico, A, el método selecciona el valor de A que tiene la entropía mínima como punto de división y divide recursivamente los intervalos resultantes para llegar a una discretización jerárquica. Tal discretización forma una jerarquía de conceptos para A. Debido a que la discretización basada en árboles de decisión usa información de clase, es más probable que los límites de intervalo (puntos de división) se definan para que ocurran en lugares que pueden ayudar a mejorar la precisión de la clasificación. Los árboles de decisión y la medida de entropía se describen con mayor detalle en la Sección 8.2.2.
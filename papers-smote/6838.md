# Un análisis integral de la técnica de sobremuestreo de minorías sintéticas (SMOTE) para manejar el desequilibrio de clases

Los problemas de clasificación desequilibrada se encuentran a menudo en muchas aplicaciones. El desafío es que hay una clase minoritaria que normalmente tiene muy pocos datos y suele ser el foco de atención. Un enfoque para manejar el desequilibrio es generar datos adicionales de la clase minoritaria, para superar su escasez de datos. La técnica de sobremuestreo de minorías sintéticas (SMOTE) es uno de los métodos dominantes en la literatura que logra esta generación de muestra adicional. Se basa en generar ejemplos sobre las líneas que conectan un punto y uno de sus K-vecinos más cercanos. Este artículo presenta un análisis teórico y experimental del método SMOTE. Exploramos la precisión de cuán fiel emula la densidad subyacente. Hasta donde sabemos, este es el primer análisis matemático del método SMOTE. Además, analizamos el efecto de los diferentes factores en la precisión de la generación, como la dimensión, el tamaño del conjunto de entrenamiento y el número considerado de vecinos K. También proporcionamos un análisis cualitativo que examina los factores que afectan su precisión. Además, exploramos el impacto de SMOTE en el límite de clasificación y el rendimiento de clasificación.

## 1. Introducción 
El aprendizaje desequilibrado es uno de los problemas más desafiantes en la minería de datos. En el aprendizaje desequilibrado tenemos una o más clases con muy pocos datos, y algunas otras con suficiente cantidad de datos. Los conjuntos de datos desequilibrados son particularmente frecuentes en los problemas de clasificación de "tipo de anomalía". Estos son una amplia categoría de problemas que se clasifican entre una clase "normal" y una clase "anomalía", donde la anomalía puede denotar una variedad de significados posibles. Algunos ejemplos son el diagnóstico médico [37] y la detección de fallas en las máquinas [28] y la detección de fraudes [6]. En este tipo de problemas la clase minoritaria merece especial atención, porque representa el fenómeno que buscamos predecir, de entre una plétora de patrones de clase mayoritaria que denotan un funcionamiento normal. Los clasificadores estándar están diseñados para minimizar el error de clasificación general independientemente de la distribución de clases. Por lo tanto, el desempeño de tales clasificadores se vuelve sesgado hacia los ejemplos de la clase mayoritaria mientras se sacrifica la precisión de la clase minoritaria. Los enfoques para manejar el problema del desequilibrio de datos se clasifican principalmente en las siguientes categorías: 
1) el enfoque sensible al costo, 
2) el enfoque de nivel de algoritmo y 
3) el enfoque de nivel de datos. 

***El enfoque sensible a los costos*** utiliza matrices de costos para establecer costos de clasificación errónea de acuerdo con la importancia de la clase y el grado de desequilibrio. Ejemplos de trabajo sobre el enfoque sensible al costo incluyen AdaCost [15] y el trabajo en [40].

***El enfoque de nivel de algoritmo*** adapta las especificaciones del algoritmo de clasificación para tener en cuenta el problema del desequilibrio. Por ejemplo, hay trabajo sobre la modificación del clasificador vecino más cercano K (KNN) [13], otro trabajo sobre la adaptación de árboles de decisión [31] y algunos enfoques que modifican las máquinas de vectores de soporte (SVM) [25,44], todo en un manera que pone especial énfasis en la(s) clase(s) minoritaria(s). El enfoque de nivel de datos se basa en modificar los datos en sí mismos al intentar reequilibrar las clases mayoritaria y minoritaria. Esto se puede realizar eliminando algunas instancias de la clase mayoritaria (muestreo insuficiente) o aumentando el número de instancias de la clase minoritaria (muestreo excesivo). Es el enfoque de desequilibrio más dominante, debido a su simplicidad y porque es un enfoque general que se puede aplicar independientemente del clasificador que se utilice. **Es simplemente una superposición de muestreo, con el clasificador intacto debajo. Este enfoque es el centro de este trabajo.** El submuestreo se realiza eliminando patrones menos importantes, ya sea mediante selección aleatoria o mediante el uso de algunas reglas heurísticas. Por ejemplo, la regla del vecino más cercano condensada [16] y la selección unilateral [2] son ​​algunos tipos de submuestreo. Sin embargo, el submuestreo es arriesgado ya que podría perderse información importante. La otra alternativa probablemente más exitosa es el sobremuestreo [2]. Se logra mediante la reproducción aleatoria de patrones de clase minoritaria o mediante la generación de nuevos patrones de clase minoritaria. Es probable que los algoritmos de muestreo se combinen con el *aprendizaje por conjuntos*. Esto significa que generamos múltiples conjuntos de muestras y para cada conjunto diseñamos un clasificador. Posteriormente, combinamos la clasificación de estos clasificadores. Ejemplos de tales modelos son SMOTEBoost [8] y el sobremuestreo de Minorías clasificadas en Boosting (RAMOBoost), que combinan conjuntos con sobremuestreo [9]. Por otro lado, otras técnicas como RUSBoost [38], EasyEnsemble y BalanceCascade [32] se basan en la creación de un conjunto de datos que consiste en una clase mayoritaria submuestreada. La ventaja del sobremuestreo es que compensa la escasez de datos de la clase minoritaria generando datos adicionales. Sin embargo, ***el problema es que no se conoce la distribución subyacente y el desafío es emular esta distribución tanto como sea posible al generar nuevos datos***. Una técnica muy exitosa para generar nuevos datos es la llamada “Técnica de sobremuestreo de minorías sintéticas”, o SMOTE [7]. Se basa en el muestreo de datos de la clase minoritaria simplemente generando puntos de datos en el segmento de línea que conecta un punto de datos seleccionado al azar y uno de sus vecinos K más cercanos. Este enfoque es muy simple y extremadamente exitoso en la práctica, por lo que se generalizó mucho. **El único problema con SMOTE [7] es que no se basa en una teoría matemática sólida**. *El propósito de este trabajo es abordar esta deficiencia y proporcionar un análisis en profundidad del procedimiento SMOTE*. En este trabajo presentamos un análisis de las características de distribución de las muestras sintéticas generadas por SMOTE. Esto ayuda a evaluar la calidad de los datos, en el sentido de qué tan bien emulan los datos generados la verdadera distribución subyacente. En nuestros experimentos evaluamos cómo los patrones sobremuestreados se desvían de la distribución original. Es importante centrarse en los aspectos distributivos, porque las distribuciones de las clases dictan la forma del límite de clasificación. Esto se da explícitamente en el caso del clasificador Bayes e implícitamente para los otros clasificadores. Aunque SMOTE no está diseñado explícitamente para reproducir la distribución subyacente, ***la distribución juega un papel fundamental en la configuración del límite de clasificación***. Además de nuestro análisis de distribución presentado, proporcionamos un análisis del impacto de SMOTE en el rendimiento de la clasificación, ya que el rendimiento de la clasificación es el objetivo final del uso de SMOTE. En concreto, nuestros objetivos son los siguientes:

• Desarrollar un análisis matemático de SMOTE y probar el grado de su emulación de la distribución subyacente (verificando sus momentos). El análisis teórico presentado es general y aplica para cualquier distribución. 
• Aplicar el análisis teórico general a dos distribuciones: Gaussiana multivariante y Laplaciana multivariante, para obtener fórmulas cerradas simplificadas para la media y covarianza de la distribución de los patrones sobremuestreados. 
• Proporcionar un estudio experimental detallado de SMOTE, explorando los factores que afectan su precisión (al imitar la distribución). Por ejemplo, encontramos, tanto teórica como empíricamente, que la precisión se deteriora cuando disminuye el número de patrones minoritarios originales, cuando aumenta la dimensión y cuando aumenta el número de vecinos utilizados para aplicar el muestreo SMOTE. 
• Explorar el desempeño de SMOTE para algunos clasificadores, tanto teórica como empíricamente, investigando también el efecto de diferentes factores en su desempeño. 
• Presentar un análisis empírico integral de SMOTE y tres extensiones populares de SMOTE (Borderline SMOTE1, Borderline SMOTE2 y Adasyn), cuyo objetivo es evaluar estos métodos de sobremuestreo en términos de rendimiento de distribución y clasificación.

El documento está organizado de la siguiente manera: la Sección 2 presenta una revisión de la literatura. La sección 3 presenta la técnica SMOTE e indica sus ventajas y posibles inconvenientes. La Sección 4 analiza la distribución de los patrones generados usando SMOTE derivando su media y matriz de covarianza. Luego, se realiza un análisis experimental para analizar SMOTE en la Sección 5. Después de eso, la Sección 6 analiza los hallazgos experimentales y teóricos y analiza algunos de los problemas y peligros de SMOTE. Finalmente, la Sección 7 concluye el documento y menciona el trabajo futuro potencial


**pruengkarn2017**
11192-Article (PDF)-20731-1-10-20180420
1-s2.0-S0950705119301042
1-s2.0-S0925231219311622
1-s2.0-S0925231214007644
**1-s2.0-S0020025519306838**, Un análisis integral de la técnica de sobremuestreo de minorías sintéticas (SMOTE) para manejar el desequilibrio de clases

1-s2.0-S0888613X18301865



{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta notebook, se van a realizar pruebas de las variantes de SMOTE. Atento a lo que plantea el paper ***\"Variantes de Smote: una implementación de Python de 85 técnicas de sobremuestreo minoritarias\"***, solo hay dos librerias que implementan SMOTE y sus variantes: imblearn y smotefamily. La primera del paquete python ofrece 7 variantes de SMOTE, y la segunda del paquete R ofrece otras 4. En este paper, la libreria smote-variants, implementa 85 variantes de SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La competencia \n",
    "\n",
    "Hemos lanzado una competencia para encontrar la mejor técnica de sobremuestreo de propósito general. La competencia está en curso, los resultados preliminares están disponibles en la página https://smote-variants.readthedocs.io/en/latest/competition.html Todos los resultados numéricos son reproducibles mediante el script de ejemplo 005_e Evaluation, descargando los plegamientos de la base de datos del enlace a continuación y siguiendo las instrucciones en el guión. Cualquiera está abierto a unirse a la competencia implementando una técnica de sobremuestreo como parte del paquete smote_variants. Los plegamientos de la base de datos a continuación se pueden usar para evaluar la técnica y comparar los resultados con los ya implementados. Una vez que el código se agrega a una rama de características, los organizadores repetirán la evaluación y los resultados se agregarán a la página de clasificación. Plegados de bases de datos: https://drive.google.com/open?id=1PKw1vETVUzaToomio1-RGzJ9_-buYjOW \n",
    "\n",
    "### Contribución \n",
    "\n",
    "Siéntase libre de implementar cualquier otra técnica de sobremuestreo y analicemos los códigos tan pronto como la solicitud de extracción esté lista.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smote_variants as sv\n",
    "import imblearn.datasets as imb_datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "libras= imb_datasets.fetch_datasets()['libras_move']\n",
    "X, y= libras['data'], libras['target']\n",
    "\n",
    "oversampler= sv.MulticlassOversampling(sv.distance_SMOTE())\n",
    "classifier= KNeighborsClassifier(n_neighbors= 5)\n",
    "\n",
    "# Constructing a pipeline with oversampling and classification as the last step\n",
    "model= Pipeline([('scale', StandardScaler()), ('clf', sv.OversamplingClassifier(oversampler, classifier))])\n",
    "\n",
    "param_grid= {'clf__oversampler':[sv.distance_SMOTE(proportion=0.5),\n",
    "                               sv.distance_SMOTE(proportion=1.0),\n",
    "                               sv.distance_SMOTE(proportion=1.5)]}\n",
    "\n",
    "# Specifying the gridsearch for model selection\n",
    "grid= GridSearchCV(model, param_grid= param_grid, cv= 3, n_jobs= 1, verbose= 2, scoring= 'accuracy')\n",
    "\n",
    "# Fitting the pipeline\n",
    "grid.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

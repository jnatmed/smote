Ahora consideramos el problema del desequilibrio de clases, donde la clase principal de interés es rara. Es decir, la distribución del conjunto de datos refleja una mayoría significativa de la clase negativa y una clase positiva minoritaria. Por ejemplo, en las aplicaciones de detección de fraude, la clase de interés (o clase positiva) es "fraude", que ocurre con mucha menos frecuencia que la clase negativa "no fraudulenta". En los datos médicos, puede haber una clase rara, como "cáncer". Suponga que ha entrenado un clasificador para clasificar tuplas de datos médicos, donde el atributo de etiqueta de clase es "cáncer" y los posibles valores de clase son "sí" y "no". Una tasa de precisión de, digamos, el 97 % puede hacer que el clasificador parezca bastante preciso, pero ¿qué pasa si solo, digamos, el 3 % de las tuplas de entrenamiento son en realidad cáncer? Claramente, una tasa de precisión del 97 % puede no ser aceptable; el clasificador podría estar etiquetando correctamente solo las tuplas no cancerosas, por ejemplo, y clasificar incorrectamente todas las tuplas cancerosas. En cambio, necesitamos otras medidas, que accedan a qué tan bien el clasificador puede reconocer las tuplas positivas (cáncer = sí) y qué tan bien puede reconocer las tuplas negativas (cáncer = no). Las medidas de sensibilidad y especificidad se pueden utilizar, respectivamente, para este propósito. La sensibilidad también se denomina tasa positiva verdadera (reconocimiento) (es decir, la proporción de tuplas positivas que se identifican correctamente), mientras que la especificidad es la tasa negativa verdadera (es decir, la proporción de tuplas negativas que se identifican correctamente). Estas medidas se definen como

## 8.6.5 Mejora de la precisión de la clasificación de los datos desequilibrados de clases 
En esta sección, revisamos el problema del desequilibrio de clases. En particular, estudiamos enfoques para mejorar la precisión de la clasificación de los datos de clase desequilibrada. Dados datos de dos clases, los datos están desequilibrados si la clase principal de interés (la clase positiva) está representada solo por unas pocas tuplas, mientras que la mayoría de las tuplas representan la clase negativa. Para datos multiclase desequilibrados, la distribución de datos de cada clase difiere sustancialmente donde, nuevamente, la clase principal o las clases de interés son raras. El problema del desequilibrio de clases está estrechamente relacionado con el aprendizaje sensible a los costos, en el que los costos de los errores, por clase, no son iguales. En el diagnóstico médico, por ejemplo, es mucho más costoso diagnosticar falsamente a un paciente canceroso como sano (falso negativo) que diagnosticar erróneamente a un paciente sano con cáncer (falso positivo). Un error de falso negativo podría provocar la pérdida de vidas y, por lo tanto, es mucho más costoso que un error de falso positivo. Otras aplicaciones que involucran datos de clase desequilibrada incluyen la detección de fraudes, la detección de derrames de petróleo a partir de imágenes de radar satelital y el monitoreo de fallas. Los algoritmos de clasificación tradicionales tienen como objetivo minimizar el número de errores cometidos durante la clasificación. Asumen que los costos de los errores falsos positivos y falsos negativos son iguales. Al suponer una distribución equilibrada de clases y costos de error iguales, no son adecuados para datos de clases desequilibradas. 
Partes anteriores de este capítulo presentaron formas de abordar el problema del desequilibrio de clases. Si bien la medida de precisión asume que los costos de las clases son iguales, se pueden utilizar métricas de evaluación alternativas que consideren los diferentes tipos de clasificaciones. La Sección 8.5.1, por ejemplo, presentó la sensibilidad o recuerdo (la tasa positiva verdadera) y la especificidad (la tasa negativa verdadera), que ayudan a evaluar qué tan bien un clasificador puede predecir la etiqueta de clase de los datos desequilibrados. Las medidas relevantes adicionales discutidas incluyen F1 y Fβ. La Sección 8.5.6 mostró cómo las curvas ROC trazan la sensibilidad frente a 1 − especificidad (es decir, la tasa de falsos positivos). Estas curvas pueden proporcionar información al estudiar el rendimiento de los clasificadores en datos de clase desequilibrada. En esta sección, analizamos los enfoques generales para mejorar la precisión de la clasificación de los datos de clase desequilibrada. Estos enfoques incluyen (1) sobremuestreo, (2) submuestreo, (3) movimiento de umbral y (4) técnicas de conjunto. Los tres primeros no implican cambios en la construcción del modelo de clasificación. Es decir, el sobremuestreo y el submuestreo cambian la distribución de tuplas en el conjunto de entrenamiento; el movimiento del umbral afecta la forma en que el modelo toma decisiones al clasificar nuevos datos. Los métodos de conjunto siguen las técnicas descritas en las Secciones 8.6.2 a 8.6.4. Para facilitar la explicación, describimos estos enfoques generales con respecto al problema de datos de desequilibrio de dos clases, donde las clases de mayor costo son más raras que las clases de menor costo. Tanto el sobremuestreo como el submuestreo cambian la distribución de datos de entrenamiento para que la clase rara (positiva) esté bien representada. El sobremuestreo funciona volviendo a muestrear las tuplas positivas para que el conjunto de entrenamiento resultante contenga el mismo número de tuplas positivas y negativas. El submuestreo funciona al disminuir el número de tuplas negativas. Elimina aleatoriamente tuplas de la clase mayoritaria (negativa) hasta que haya el mismo número de tuplas positivas y negativas.